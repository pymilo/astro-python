{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".input_prompt, .CodeMirror-lines, .output_area\n",
       "{\n",
       "  font-family: Consolas;\n",
       "  font-size: 120%;\n",
       "  }\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PyTables and HDF5\n",
    "-----------------------\n",
    "UC Berkeley Python class (AY250; 2013-2016)\n",
    "\n",
    "\n",
    "*\"PyTables presents a database-like approach to data storage, providing features like indexing and fast “in-kernel” queries on dataset contents. It also has a custom system to represent data types.\" -- http://docs.h5py.org/en/latest/faq.html#what-s-the-difference-between-h5py-and-pytables*\n",
    "\n",
    "First we'll open a new HDF5 for writing (note: the \"w\" implies we will overwrite the file we have on disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-b725882abc68>\", line 3, in <module>\n",
      "    h5file = open_file(\"spam.h5\",mode = \"w\", title = \"PyTables/HDF5 test file\")\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/site-packages/tables/file.py\", line 318, in open_file\n",
      "    return File(filename, mode, title, root_uep, filters, **kwargs)\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/site-packages/tables/file.py\", line 784, in __init__\n",
      "    self._g_new(filename, mode, **params)\n",
      "  File \"tables/hdf5extension.pyx\", line 488, in tables.hdf5extension.File._g_new (tables/hdf5extension.c:5593)\n",
      "tables.exceptions.HDF5ExtError: HDF5 error back trace\n",
      "\n",
      "  File \"H5F.c\", line 522, in H5Fcreate\n",
      "    unable to create file\n",
      "  File \"H5Fint.c\", line 1003, in H5F_open\n",
      "    unable to open file: time = Fri Sep 30 14:27:44 2016\n",
      ", name = 'spam.h5', tent_flags = 13\n",
      "  File \"H5FD.c\", line 993, in H5FD_open\n",
      "    open failed\n",
      "  File \"H5FDsec2.c\", line 339, in H5FD_sec2_open\n",
      "    unable to open file: name = 'spam.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 602\n",
      "\n",
      "End of HDF5 error back trace\n",
      "\n",
      "Unable to open/create file 'spam.h5'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'HDF5ExtError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/inspect.py\", line 701, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/inspect.py\", line 685, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/Kamilobu/anaconda/envs/ay250/lib/python3.5/posixpath.py\", line 361, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"H5F.c\", line 522, in H5Fcreate\n    unable to create file\n  File \"H5Fint.c\", line 1003, in H5F_open\n    unable to open file: time = Fri Sep 30 14:27:44 2016\n, name = 'spam.h5', tent_flags = 13\n  File \"H5FD.c\", line 993, in H5FD_open\n    open failed\n  File \"H5FDsec2.c\", line 339, in H5FD_sec2_open\n    unable to open file: name = 'spam.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 602\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'spam.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tables import *\n",
    "h5file = open_file(\"spam.h5\",mode = \"w\", title = \"PyTables/HDF5 test file\")\n",
    "h5file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters sets the protocols for the way all data will be treated in the file. `fletcher32 = True`, for instance will enforce checksums (slower, but more stable data), `complevel` is the compression level, etc.\n",
    "\n",
    "Now, let's create a 100$\\times$100 random image with `create_array` and associate it with a group called \"Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbloom/anaconda/envs/seminar/lib/python3.5/site-packages/ipykernel/__main__.py:2: DeprecationWarning: createArray() is pending deprecation, use create_array() instead. You may use the pt2to3 tool to update your source code.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "/Datasets/dataset1 (Array(100, 100)) 'Test data set #1'\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = h5file.create_group(h5file.root, \"Datasets\", \"Test data sets\")\n",
    "h5file.create_array(datasets, 'dataset1', np.random.random((100,100)), \"Test data set #1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a complex object which we'll call a \"Particle\" that has the properties like name, atomic number, mass, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Particle(IsDescription):\n",
    "    name        = StringCol(16, pos=1) # 16-character String\n",
    "    atomic_num  = IntCol(pos=2)        # integer\n",
    "    mass        = FloatCol(pos=3)      # double (double-precision)\n",
    "    pressure    = Float32Col(shape=(2,3))\n",
    "table1 = h5file.create_table(datasets, \"particles\", Particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Datasets/particles.row (Row), pointing to row #0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = table1.row\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some data into the first particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'oxygen', 8, 15.9994, [[1.0, 2.0, 3.0], [-1.0, 1.0, 3.0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[\"name\"] = \"oxygen\"\n",
    "row[\"atomic_num\"] = 8\n",
    "row[\"mass\"] = 15.9994\n",
    "row[\"pressure\"] = [[1,2,3],[-1,1,3]]\n",
    "row.append() ; table1.flush()\n",
    "h5file.root.Datasets.particles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, unlike numpy arrays, we can append new data. So this seems more like a DB in this respect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'bezerkilum', 150, 360.0, [[1.0, 2.0, 3.0], [1.0, 0.0, 3.0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = table1.row\n",
    "row[\"name\"] = \"bezerkilum\"\n",
    "row[\"atomic_num\"] = 150\n",
    "row[\"mass\"] = 360.0\n",
    "row[\"pressure\"] = [[1,2,3],[1,0,3]]\n",
    "row.append() ; table1.flush()\n",
    "h5file.root.Datasets.particles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oxygen']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row['name'].decode() for row in table1.where('(atomic_num > 5) & (mass < 100.0)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oxygen\n",
      "bezerkilum\n"
     ]
    }
   ],
   "source": [
    "for row in table1:\n",
    "    print(row[\"name\"].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5py\n",
    "\n",
    "Groups work like dictionaries, and datasets work like NumPy arrays\n",
    "\n",
    "http://docs.h5py.org/en/latest/quick.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"spam-h5py.h5\" (mode r+)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "!rm spam-h5py.h5\n",
    "h5file = h5py.File(\"spam-h5py.h5\",mode = \"w\", title = \"h5py/HDF5 test file\")\n",
    "h5file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In h5py, \"Datasets are very similar to NumPy arrays. They are homogenous collections of data elements, with an immutable datatype and (hyper)rectangular shape. Unlike NumPy arrays, they support a variety of transparent storage features such as compression, error-detection, and chunked  I/O.\" -- http://docs.h5py.org/en/latest/high/dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = h5file.create_group(\"Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset2\": shape (100, 100), type \"<f8\">"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.create_dataset('Datasets/dataset1', data=np.random.random((100,100)))\n",
    "datasets.create_dataset('Datasets/dataset2', data=np.random.random((100,100)),\n",
    "                        compression=\"gzip\", compression_opts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = datasets.get('Datasets/dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97794214,  0.11794942,  0.39368585, ...,  0.7658321 ,\n",
       "         0.78288034,  0.9464316 ],\n",
       "       [ 0.76573763,  0.8718638 ,  0.7027056 , ...,  0.01710255,\n",
       "         0.92814481,  0.80044144],\n",
       "       [ 0.33383122,  0.53455644,  0.91913964, ...,  0.57837372,\n",
       "         0.56180651,  0.10364729],\n",
       "       ..., \n",
       "       [ 0.23370288,  0.43693144,  0.73115798, ...,  0.93510635,\n",
       "         0.67461141,  0.38052106],\n",
       "       [ 0.30162771,  0.62406416,  0.83488421, ...,  0.14604748,\n",
       "         0.83666988,  0.26251197],\n",
       "       [ 0.14676648,  0.43856595,  0.16412232, ...,  0.55433556,\n",
       "         0.70228834,  0.0908137 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53455644,  0.55951379,  0.27516592],\n",
       "       [ 0.0754908 ,  0.62502142,  0.9400895 ],\n",
       "       [ 0.64286464,  0.44354353,  0.2552696 ],\n",
       "       [ 0.93754221,  0.16648524,  0.9980154 ],\n",
       "       [ 0.40565599,  0.30440593,  0.13540566],\n",
       "       [ 0.64642334,  0.89577348,  0.71847996],\n",
       "       [ 0.81442915,  0.47496836,  0.80107197],\n",
       "       [ 0.18471405,  0.780301  ,  0.21541965]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2:10,1:9:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = [(\"name\",\"S16\"),(\"atomic_num\",\"i4\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Particle\": shape (100, 1), type \"|V20\">"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.create_dataset(\"Particle\", shape=(100,1), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdata = datasets.get(\"Particle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdata[0] = (\"oxygen\",8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'oxygen', 8)]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"spam-h5py.h5\",mode = \"r\") as f:\n",
    "    pdata = f.get(\"Datasets/Particle\")\n",
    "    print(pdata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [ay250]",
   "language": "python",
   "name": "Python [ay250]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
