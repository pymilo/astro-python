{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ../00_AdvancedPythonConcepts/talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism\n",
    "\n",
    "Python Computing for Data Science (AY250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline for Today\n",
    "\n",
    "- Motivation\n",
    "\n",
    "- Single-machine\n",
    "    - threading\n",
    "    - multiprocessing\n",
    "    - joblib\n",
    "    - dask\n",
    "- Multi-machine\n",
    "    - ipython cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Generally, the goal of your computing task is to finish as quickly as possible. The **speed of your processor** at executing instructions and the **speed at which data can be read from disk and from RAM** are major contributors to the execution time. Obviously the **choice of algorithm(s)** is critical too. Choosing an $N \\log N$ algorithm over a $N^2$ one that gets the same answer is almost always preferred for any sizeable $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Bottlenecks\n",
    "\n",
    "If you think of your run-time program as stream of data and computation on data, it should be clear that **bottlenecks are inevitable**. Your job (as you begin optimize for execution time) is to understand where those bottlenecks are and to use the tools we have in Python to minimize those. (Ultimately, it's a never-ending whack-a-mole).\n",
    "\n",
    "#### I/O Bound\n",
    "\n",
    "*\"a condition in which the time it takes to complete a computation is determined principally by the period spent waiting for input/output operations to be completed.\"* -- wikipedia\n",
    "\n",
    "This can be because we're waiting for a response from an external source (e.g. loading a webpage) or because data needs to be moved around on your bus and we're waiting for it to show up in the right place to compute on. If you have very fast CPUs, you're more likely to be I/O bound.\n",
    "\n",
    "#### CPU Bound\n",
    "\n",
    "*\"when the time for it to complete a task is determined principally by the speed of the central processor: processor utilization is high, perhaps at 100% usage for many seconds or minutes.\"* -- wikipedia\n",
    "\n",
    "If you're doing  algorithmic computations where the amount if input data is small and the amount of output data is also small (e.g. fournier transform) you'll typically be CPU bound. Slowed CPUs lead to more CPU bound bottlenecks. If you have a lot of data (\"big\") you're moving data around from disk, RAM, cache and you're likely I/O bound.\n",
    "\n",
    "#### (Memory Bound)\n",
    "\n",
    "\"time to complete a given computational problem is decided primarily by the amount of memory required to hold data\" - wikipedia.\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AUUzntxvU9BHWJMZSH_CL3S7YRUjThJTrPEB/image.png\">\n",
    "\n",
    "Source: http://www.slideshare.net/ManojitNandi/parallel-programming-in-python-speeding-up-your-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processes & Threads\n",
    "\n",
    "Each Python interpreter runs in a `process,` containing the program code, stack, and its current activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a process one can create a set of `threads` which share everything with the process in which they were spawned (memory, data, state). But, most generally, they are little programs (with their own stack) that execute `concurrently` (independent of each other). Since they share things like memory, it requires the programmer to \"lock\" everything that might conflict. The way we make many threads in Python is using the `threading` module.\n",
    "\n",
    "<div class=\"alert alert-info\">The Global Interpreter Lock (GIL) in Python stops threads from truly happening in parallel. That is, the interpreter can only operate one thread at a time. This is an impliementation detail of how CPython was programmed. Many things you use push threads down into the C-layer and \"avoid the GIL\". </div>\n",
    "\n",
    "You can also make many processes, which are copies of the original parent process (memory, data, state) and act independently of each other. To share data between them you have to explicitly do that within each process. The Pythonic way we do multiprocessing (creation of new processes, communication between processes) is with `multiprocessing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of computing with `threading` and `multiprocessing` is to not wait around: the CPU should not be idle if it doesn't have too. AND since we almost always have multiple cores, we should be able to let the work we want to do happen in parallel over those cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threading\n",
    "\n",
    "`threading.Thread(target=f, args=(...))` is the basic way to use function `f` with arguments in a thread.\n",
    "\n",
    "`.start()`: Calls the `.run()` of a thread object. This method will raise a `RuntimeError` if called more than once on the same thread object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    print('Worker: %s' % num)\n",
    "    return\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Nice profile to let us profile\n",
    "!pip install snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%snakeviz\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the GIL, threads wont get in each other's way if they are idle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(%(threadName)-9s) %(message)s',)\n",
    "\n",
    "import threading\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    \n",
    "    sleep_time = random.randint(1,5)\n",
    "    logging.debug('worker: {0} sleeping for {1} s, name: {2}'\n",
    "                   .format(num,sleep_time,threading.current_thread().getName()))\n",
    "    time.sleep(sleep_time)\n",
    "    logging.debug('done')\n",
    "    return\n",
    "\n",
    "threads = []\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# not very parallel ... \n",
    "threads = []\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "    t.join() # this waits for the thread to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threads = []\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "\n",
    "print(\"waiting around a bit, then starting threads\",flush=True)\n",
    "time.sleep(2)\n",
    "\n",
    "# dont have to start a thread immediately after creating them\n",
    "for t in threads:\n",
    "    t.start() \n",
    "\n",
    "for t in threads:\n",
    "    t.join() # this waits for the thread to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things:\n",
    "\n",
    "- `logging` is \"thread-safe\" -- so different threads can write to the log file without causing issues\n",
    "- you can always get a handle to the current thread with `threading.current_thread()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can delay the start of the execution of a thread with `Timer`\n",
    "\n",
    "```python\n",
    "threading.Timer(interval, function, args=None, kwargs=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threads = []\n",
    "for i in range(2):\n",
    "    r = random.randint(1,5)\n",
    "    t = threading.Timer(r, worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    logging.debug(\"starting {0} with delay {1}\"\n",
    "                  .format(t.getName(),r))\n",
    "    threads[-1].start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can share variables (safely) between threads with a `queue`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "def worker2(num):\n",
    "    sleep_time = random.randint(1,5)\n",
    "    \n",
    "    logging.debug('worker: {0} sleeping for {1} s, name: {2}'\n",
    "                   .format(num,sleep_time,threading.current_thread().getName()))\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    if q.empty():\n",
    "        q.put(sleep_time)\n",
    "        logging.debug(\"initiated q = {0}\".format(sleep_time))\n",
    "    else:\n",
    "        var = q.get()\n",
    "        logging.debug(\"var {0}\".format(var))\n",
    "        q.put(sleep_time + var)\n",
    "        logging.debug(\"added {0} to the q\".format(sleep_time))\n",
    "        \n",
    "    logging.debug('done')\n",
    "    return\n",
    "\n",
    "threads = []\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker2, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threads can also signal each other with `Event` and can thresholds for the numbers of finished threads can be created with `Barrier`. There are low-level primiatives (pushed to the UNIX \\_pthreads level) called `locks` and `semaphores` that we'll not bother with here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threading can be done with objects. You can subclass `threading.Thread` and create your own threads that know how to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.popen(\"ping -q -c2 cnn.com\",\"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adapted from http://www.python-course.eu/threads.php\n",
    "import os, re, threading\n",
    "\n",
    "received_packages = re.compile(r\"(\\d) packets received\")\n",
    "\n",
    "class ip_check(threading.Thread):\n",
    "  \n",
    "    def __init__ (self,ip):\n",
    "      threading.Thread.__init__(self)\n",
    "      self.ip = ip\n",
    "      self.__successful_pings = -1\n",
    "   \n",
    "    def run(self):\n",
    "      ping_out = os.popen(\"ping -q -c2 \"+self.ip,\"r\")\n",
    "      while True:\n",
    "        lines = ping_out.readlines()\n",
    "        if not lines or len(lines) < 3: \n",
    "            break\n",
    "        n_received = re.findall(received_packages,lines[3])\n",
    "        if n_received:\n",
    "           self.__successful_pings = int(n_received[0])\n",
    "        \n",
    "    def status(self):\n",
    "      if self.__successful_pings == 0:\n",
    "         return \"has no response\"\n",
    "      elif self.__successful_pings == 1:\n",
    "         return \"is alive, but 50 % package loss\"\n",
    "      elif self.__successful_pings == 2:\n",
    "         return \"is alive\"\n",
    "      else:\n",
    "         return \"not reachable\"\n",
    "\n",
    "check_results = []\n",
    "for ip in [\"google.com\",\"slashdot.com\",\"berkeley.edu\",\"blasaskaslkas.org\"]:\n",
    "   current = ip_check(ip)\n",
    "   check_results.append(current)\n",
    "   current.start()\n",
    "\n",
    "for el in check_results:\n",
    "   el.join()\n",
    "   print(\"Status of\", el.ip,el.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout\n",
    "\n",
    "Using threading, grab the titles of random 10 wikipedia webpages using https://en.wikipedia.org/wiki/Special:Random. Count the total number of characters returned over all 10 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: for asynchronous I/O tasks you might consider using an event loop. Use the built in `asyncio` and, for gathering webpages, use `aiohttp` (http://aiohttp.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.read()\n",
    "\n",
    "async def run(loop,  r):\n",
    "    url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "    tasks = []\n",
    "\n",
    "    # Fetch all responses within one Client session,\n",
    "    # keep connection alive for all requests.\n",
    "    async with ClientSession() as session:\n",
    "        for i in range(r):\n",
    "            task = asyncio.ensure_future(fetch(url, session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        # you now have all response bodies in this variable\n",
    "    \n",
    "    for resp in responses:\n",
    "        print(\"title=\",BeautifulSoup(resp, 'html.parser')\n",
    "              .title.string.split(\"- Wikipedia\")[0],\"len=\",len(resp))\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "future = asyncio.ensure_future(run(loop, 4))\n",
    "loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
